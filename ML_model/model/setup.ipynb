{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Training Script\n",
    "To be run after new videos are added\n",
    "\n",
    "Based on the article [Guide to Build Video Classification Model](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/amandaly/Library/Python/3.7/lib/python/site-packages (from opencv-python) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "import cv2  # for caputring videos\n",
    "import math # for mathematical operations\n",
    "import matplotlib.pyplot as plt # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from numpy import genfromtxt\n",
    "from skimage.transform import resize # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Turn the csv files into dictionaries\n",
    "1. Opens and converts csv file\n",
    "2. Gets tags\n",
    "3. Gets points for each frame\n",
    "4. Reshapes each frame array\n",
    "5. Groups frames by three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going into folder with training data\n",
    "path=\"dataPoints_training/\"\n",
    "\n",
    "# creating a pandas dataframe \n",
    "train = pd.DataFrame()\n",
    "\n",
    "# going into individual files\n",
    "for filename in glob(os.path.join(path, '*.csv')):\n",
    "    # go into each file and add all of the data into the train dataframe\n",
    "    file = filename.split(\"/\")[1]  # gets individual file name\n",
    "    train = pd.read_csv(path + file, header=None)  # adds data to dataframe\n",
    "\n",
    "    # creating empty dictionary named trainingFrames_FILENAME\n",
    "    locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    # creating empty dictionary named trainingCombo_FILENAME\n",
    "    locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    \n",
    "    #getting tag for each set of points from name of file\n",
    "    tag =filename.split(\"/\")[1].split(\"_\")[3].split(\".csv\")[0]\n",
    "    # creating tag key for each trainingCombo dictionary and adding tag value\n",
    "    locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"] = tag\n",
    "\n",
    "    # number of points per frame\n",
    "    n = 12\n",
    "    \n",
    "    # create array for each frame and adds them to dictionary\n",
    "    for i in range(len(train) // 12):\n",
    "        # grouping each frame and making one big array (with 12 x,y points) aka grouping 12 arrays into one array\n",
    "        data = train.to_numpy()[i * n:(i + 1) * n]\n",
    "        # deleting frame number from above array\n",
    "        data = np.delete(data, 0, 1)\n",
    "        # reshaping each frame array into 24, 1\n",
    "        data = np.reshape(data, (24, 1))\n",
    "        # creating tag with name of number of frame and adding above array as value into trainingFrames\n",
    "        locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "        \n",
    "\n",
    "    # goes into each trainingFrame dictionary\n",
    "    for i in locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]:\n",
    "        # if the point (???) is \n",
    "        if int(i) < (len(locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]))-2:\n",
    "            # counters for one and two above current frame respectively\n",
    "            j = int(i)+1\n",
    "            k = int(i)+2\n",
    "            \n",
    "            # creating local varriables that store current frame array and the two following\n",
    "            combine = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "            combineTwo = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "            combineThree = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(k)]\n",
    "            \n",
    "            # appending current frame with the following two frames\n",
    "            combine = np.append(combine, combineTwo, axis=1)\n",
    "            combine = np.append(combine, combineThree, axis=1)\n",
    "            \n",
    "            # creating tag with name of number of frame and adding above combo into trainingCombo\n",
    "            locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = combine  \n",
    "# print(trainingCombo_training_file_1_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all the training frames into a dummy thicc array and make them tags numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going into folder with training data\n",
    "path=\"dataPoints_training/\"\n",
    "\n",
    "# create two empty arrays\n",
    "points = []\n",
    "tags = []\n",
    "\n",
    "# going into individual files\n",
    "for filename in glob(os.path.join(path, '*.csv')): \n",
    "    # go into each file and add all of the data into the train dataframe\n",
    "    file = filename.split(\"/\")[1]\n",
    "    \n",
    "    size = len(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])])\n",
    "    \n",
    "    for i in range(0, size-1):\n",
    "        val = list(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"{}\".format(i)])\n",
    "        points.append(val)\n",
    "    \n",
    "    # add a tag for each frame in trainingCombo (??)\n",
    "    for i in range(0, size-1):\n",
    "        tags.append(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"])\n",
    "    \n",
    "X = np.array(points)\n",
    "\n",
    "tags = pd.DataFrame(tags)\n",
    "\n",
    "# replace tags of \"b\" or \"g\" with 1 and 0. (1 represents bad and 0 represents good)\n",
    "tags = tags.replace(\"b\", 1)\n",
    "tags = tags.replace(\"g\", 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.bitdegree.org/learn/train-test-split\n",
    "# discuss more in depth with RW\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, tags, test_size=0.2)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape into single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((839, 24, 3), (671, 24, 3), (168, 24, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((671, 1), (168, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((671, 24, 3), (168, 24, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(y_train.shape[0], 24*3)\n",
    "X_valid = X_valid.reshape(y_valid.shape[0], 24*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((24*3,)))    # input layer\n",
    "model.add(Dense(units=10, activation='sigmoid', input_shape=(24*3,))) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                730       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 752\n",
      "Trainable params: 752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch â€• In the context of training a model, refers to one iteration where the model sees the whole training set to update its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 671 samples, validate on 168 samples\n",
      "Epoch 1/15\n",
      "671/671 [==============================] - 1s 822us/step - loss: 0.6593 - accuracy: 0.6334 - val_loss: 0.6648 - val_accuracy: 0.6250\n",
      "Epoch 2/15\n",
      "671/671 [==============================] - 0s 518us/step - loss: 0.6709 - accuracy: 0.6095 - val_loss: 0.6667 - val_accuracy: 0.6190\n",
      "Epoch 3/15\n",
      "671/671 [==============================] - 0s 373us/step - loss: 0.6776 - accuracy: 0.5931 - val_loss: 0.6648 - val_accuracy: 0.6190\n",
      "Epoch 4/15\n",
      "671/671 [==============================] - 0s 398us/step - loss: 0.6776 - accuracy: 0.5931 - val_loss: 0.6673 - val_accuracy: 0.6190\n",
      "Epoch 5/15\n",
      "671/671 [==============================] - 0s 359us/step - loss: 0.6772 - accuracy: 0.5931 - val_loss: 0.6671 - val_accuracy: 0.6190\n",
      "Epoch 6/15\n",
      "671/671 [==============================] - 0s 372us/step - loss: 0.6770 - accuracy: 0.5931 - val_loss: 0.6663 - val_accuracy: 0.6190\n",
      "Epoch 7/15\n",
      "671/671 [==============================] - 0s 359us/step - loss: 0.6773 - accuracy: 0.5931 - val_loss: 0.6668 - val_accuracy: 0.6190\n",
      "Epoch 8/15\n",
      "671/671 [==============================] - 0s 374us/step - loss: 0.6780 - accuracy: 0.5931 - val_loss: 0.6656 - val_accuracy: 0.6190\n",
      "Epoch 9/15\n",
      "671/671 [==============================] - 0s 470us/step - loss: 0.6770 - accuracy: 0.5931 - val_loss: 0.6686 - val_accuracy: 0.6190\n",
      "Epoch 10/15\n",
      "671/671 [==============================] - 0s 374us/step - loss: 0.6780 - accuracy: 0.5931 - val_loss: 0.6656 - val_accuracy: 0.6190\n",
      "Epoch 11/15\n",
      "671/671 [==============================] - 0s 548us/step - loss: 0.6775 - accuracy: 0.5931 - val_loss: 0.6653 - val_accuracy: 0.6190\n",
      "Epoch 12/15\n",
      "671/671 [==============================] - 0s 343us/step - loss: 0.6784 - accuracy: 0.5931 - val_loss: 0.6665 - val_accuracy: 0.6190\n",
      "Epoch 13/15\n",
      "671/671 [==============================] - 0s 355us/step - loss: 0.6768 - accuracy: 0.5931 - val_loss: 0.6657 - val_accuracy: 0.6190\n",
      "Epoch 14/15\n",
      "671/671 [==============================] - 0s 346us/step - loss: 0.6776 - accuracy: 0.5931 - val_loss: 0.6650 - val_accuracy: 0.6190\n",
      "Epoch 15/15\n",
      "671/671 [==============================] - 0s 332us/step - loss: 0.6766 - accuracy: 0.5931 - val_loss: 0.6699 - val_accuracy: 0.6190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x139021ad0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid), callbacks=[mcp_save], batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this show us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ranges from 45-68%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((671, 72), (168, 72), (671, 1), (168, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning the model architecture\n",
    "model = Sequential()\n",
    "model.add(InputLayer((24*3,)))    # input layer\n",
    "model.add(Dense(units=10, activation='sigmoid', input_shape=(24*3,))) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('weight.hdf5')\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "nPredict = [0] \n",
    "actual = [] \n",
    "\n",
    "# putting actual tags of frames into actual[]\n",
    "act = y_valid.to_numpy().tolist()\n",
    "for item in act:\n",
    "    actual.append(item)\n",
    "\n",
    "# converting predictionTags list to same format as actual[] and putting it into predict[]\n",
    "predictionTags = model.predict_classes(X_valid)\n",
    "for i in range(len(predictionTags)):\n",
    "    nPredict[0] = predictionTags[i]\n",
    "    predict.append(nPredict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of test: 168 168 \n",
      "\n",
      "predict tags [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "actual tags [[1], [0], [1], [0], [0], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [1], [1], [0], [0], [0], [1], [0], [1], [0], [1], [0], [0], [0], [0], [1], [0], [1], [0], [1], [0], [0], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [1], [1], [1], [1], [0], [1], [0], [1], [0], [0], [1], [0], [0], [1], [0], [0], [1], [0], [1], [0], [0], [0], [0], [0], [0], [1], [0], [1], [0], [1], [0], [0], [0], [1], [0], [1], [1], [1], [1], [0], [1], [0], [0], [0], [1], [1], [1], [0], [0], [1], [0], [1], [1], [0], [0], [0], [1], [0], [1], [1], [0], [0], [0], [0], [1], [1], [0], [0], [1], [0], [1], [1], [1], [1], [1], [0], [0], [1], [0], [1], [1], [0], [0], [0], [1], [0], [0], [0], [0], [1], [1], [1], [1], [0], [0], [1], [0], [1], [0], [0]]\n",
      "\n",
      "num of differences 63\n"
     ]
    }
   ],
   "source": [
    "print(\"length of test:\",len(predict),len(actual),'\\n')\n",
    "print('predict tags', predict)\n",
    "print('actual tags', actual)\n",
    "\n",
    "print('\\nnum of differences', abs(predict.count(0)-actual.count([0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input video to obtain score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going into folder with training data\n",
    "path=\"dataPoints_input/\"\n",
    "\n",
    "# creating a pandas dataframe \n",
    "train = pd.DataFrame()\n",
    "\n",
    "# get name of csv, assuming it's called vids\n",
    "file = \"vid.csv\"\n",
    "\n",
    "train = pd.read_csv(path + file, header=None)\n",
    "\n",
    "# creating empty dictionary named videoFrames_FILENAME\n",
    "locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "# creating empty dictionary named videoCombo_FILENAME\n",
    "locals()['videoCombo{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "\n",
    "# number of points per frame\n",
    "n = 12\n",
    "    \n",
    "# create array for each frame and adds them to dictionary\n",
    "for i in range(len(train) // 12):\n",
    "    # grouping each frame and making one big array (with 12 x,y points) aka grouping 12 arrays into one array\n",
    "    data = train.to_numpy()[i * n:(i + 1) * n]\n",
    "    # deleting frame number from above array\n",
    "    data = np.delete(data, 0, 1)\n",
    "    # reshaping each frame array into 24, 1\n",
    "    data = np.reshape(data, (24, 1))\n",
    "    # creating tag with name of number of frame and adding above array as value into trainingFrames\n",
    "    locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "# print(videoFrames_vid)\n",
    "\n",
    "# goes into each trainingFrame dictionary\n",
    "for i in locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]:\n",
    "    # if the point (???) is \n",
    "    if int(i) < (len(locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]))-2:\n",
    "        # counters for one and two above current frame respectively\n",
    "        j = int(i)+1\n",
    "        k = int(i)+2\n",
    "            \n",
    "        # creating local varriables that store current frame array and the two following\n",
    "        combine = locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "        combineTwo = locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "        combineThree = locals()['videoFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(k)]\n",
    "            \n",
    "        # appending current frame with the following two frames\n",
    "        combine = np.append(combine, combineTwo, axis=1)\n",
    "        combine = np.append(combine, combineThree, axis=1)\n",
    "            \n",
    "        # creating tag with name of number of frame and adding above combo into trainingCombo\n",
    "        locals()['videoCombo{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = combine  \n",
    "        \n",
    "# print(videoFrames_vid['0'])\n",
    "# # print(len(videoFrames_vid['0']))\n",
    "# print(videoCombo_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "isize = len(locals()['videoCombo{}'.format(\"_\" + file.split(\".csv\")[0])])\n",
    "\n",
    "pts = []\n",
    "\n",
    "for i in range(0, isize-1):\n",
    "    val = list(locals()['videoCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"{}\".format(i)])\n",
    "    pts.append(val)\n",
    "    \n",
    "data = np.array(pts)\n",
    "X = data.reshape(data.shape[0], 24*3)\n",
    "\n",
    "p = []\n",
    "nP = [0]\n",
    "\n",
    "pTags = model.predict_classes(X)\n",
    "print(pTags)\n",
    "for i in range(len(pTags)):\n",
    "    nP[0] = pTags[i]\n",
    "    p.append(nP[0])\n",
    "    \n",
    "# go into predict and calc the percentages of good vs bad ie 0 vs 1\n",
    "numGood = 0\n",
    "size = len(p)\n",
    "for i in range(len(p)):\n",
    "    numGood = p.count(0)\n",
    "accuracy = numGood/size * 100\n",
    "print(accuracy)\n",
    "\n",
    "# where in video is it bad (1) ?\n",
    "for i in range(len(p)):\n",
    "    if p[i] == 1:\n",
    "        print(i,end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
